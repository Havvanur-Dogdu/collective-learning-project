{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d8e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebdc7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rotation_forest import RotationForestClassifier, RotationTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c77063a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\datasets\\load.py:1429: FutureWarning: The repository for interpress_news_category_tr_lite contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/interpress_news_category_tr_lite\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#veri setinin indirilmesi\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('interpress_news_category_tr_lite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34e34e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarihten sınıfta kaldık bugün tarihe damgasını vuran osmanlı i̇mparatorluğu nun kuruluş yıldönümü. adına dizilerin çekildiği tarihimizi ne kadar biliyoruz? gerekçeler faklı; ama sonuç aynı çıktı. tarihten sınıfta kaldık. sayfa 5r 1 bugün tarihe damgasını vuran osmanlı i̇mparatorluğumun kuruluş yıldönümü. adına dizilerin çekildiği tarihimizi ne kadar biliyoruz? gerekçeler faklı; ama sonuç aynı çıktı. tarihten sınıfta kaldık 7 ocak 1299... kıtalara dağılan ücüyle, ülkeler arasında gördüğü aygıyla tarihe damgasını vuran anlı devletin kuruluş tarihi. peki, anlı tarihimizi ne kadar biliyoruz? on zamanlarda tarihimizi anlatan izilere ilgi nasıl? bu dizilerde anlatanlar ne kadar sağlıklı? i̇şte sokaın değerlendirmesi; levlüdiye karaman (42-ev lamım):  bir bilgim yok. tarihle izla ilgilenmiyorum. eşim daha ilgilidir bu konuda. evde anlatır, ndan duyduklarımla yetiniyorum esem yalan olmaz. osmanlı döeminde yaşamak isterdim. tarih izileri izlerim muhteşem yüzyıl izisini çok izledim; hatta hiç kaırmazdım. ama tarihimiz bu değil. sunuün bilincindeyim. muhteşem  üzyıl dizisi genelde haremiyle ön landaydı. onun için tarihi diziden ğrenmeyi de doğru bulmuyorum. )kullarda verilen tarih dersleri yeisiz. daha çok tanıtabilirler. görel anlatım yapılsın çocuklarımız aten okumak istemiyor. en azman eğlenceli hale getirip bu şekilde ilgilendirebilirler.  erdi üstün  (22-saatçi):  bu gün osmanlı devleti nin kuruluş yıldönümü olduğunu bilmiyordum. o dönemde yaşamak isterdim. tarih yazılmış neden yaşamak istemeyim ki. tarihime yeterince hakim olduğumu düşünüyorum. araştırmalar yapıyorum. merak ediyorum. okullarda verilen tarih dersleri yeterli. tarih dizisi izlemem, televizyondan tarihimi öğrenmek bana mantıklı gelmiyor. yeterli olabilir; ama hikayeleştiriliyor. sonuçta olduğu gibi anlatılsa daha iyi olur.  songül karabacak (40-ev hanımı):  kuruluş yıldönümü olduğunu bilmiyordum. tarih bilgim çok azdır. zaten biz yaşadığımız dönemde tarih yazıyoruz. osmanlı dönemi nde yaşamak istemezdim. sebebini bilmiyorum; ama hayatımdan memnunum, dönemden de memnunum. dizileri takip etmiyorum. ama mutlaka dizilerde tarihimiz doğru yansıtılıyor ki insanlar sürekli takip ediyor. benim televizyonla pek aram yoktur.  ertuğrul şahin (47-çalışmıyor):  kuruluş yıldönümü olduğunu bilmiyordum. sizden öğrendim. o dönemde yaşamak isterdim. tarih sonuçta merak ederim. tarihle ilgili çok bilgim yok. okumadım, zaten şartlar el vermedi. okullarda verilen eğitim yeterli değil. örnek vermek gerekirse; 20 yaşında oğlum var atatürk ün doğum yılını soruyorum yüzüme bakıyor. verilen eğitim belli. konu belirliyorlar onun dışına çıkmıyorlar. daha fazla bilgi verilebilir. tabi gençlerimizde de suç var bize baksınlar tarihimizi bilmiyoruz. onlar araştırma yapsınlar her gün internette geziyorlar faydasız bir şeye bakacaklarına ecdatlarını okusunlar. tarih dizlerini izlerim. ama doğru yansıtılıyor mu orasını bilmiyorum sadece izleyiciyim. ama önceden süleyman şah ı duyardım. büyüklerimiz anlatırdı bunu diziden teyit ettim mesela.  ahmet efe (22-muhasebeci):  kuruluş yıldönümü olduğuyla ilgili bir bilgim yok. o dönemde yaşamak isterdim. aldığımız bilgiler sonucunda illa ki bir özenme oluyor. tam anlamıyla tarih bilgisine sahip olduğumu düşünmüyorum. tarihe merakım var aslında; ama çok kısıtlı araştırma yapıyorum. okullarda verilen tarih dersi yeterli değil. çünkü şuradan birkaç çocuğu çevirip sorsanız size yeterli bilgi vermez. veremez onun da bilgisi yok sonuçta. zaten kısıtlı bilgiler veriliyor. tarih dizilerini kılıç kalkan kuşanıp izliyorum. doğru yansıtılıyor bundan dolayı da biraz insanlar tarihini öğrenmeye başladı desek yalan olmaz. bu ne kadar doğru derseniz de bilgiyi doğru verdikten sonra tabi diziden de tarih öğrenilebilir.  mehmet ak (28-satış danışmanı):  kuruluşunun bugün olduğunu bilmiyordum. o dönemde yaşamak isterdim. yeterli bilgim yok bence kim tarihi tam anlamıyla öğrenebilir ki zaten. ama tabi tarih kitapları okuyorum, araştırıyorum. okullarda verilen tarih derslerini yeterli bulmuyorum; ama daha fazla neler yapılabilir, tarih küçüklere nasıl anlatılır bilmiyorum tek bildiğim yeterli olmadığı. tarih dizileri gerçeği yüzde 75 yansıtıyor. bu konuda araştırma yaptım yüzeysel anlatılıyor; fakat yine de bilgi edinilebilecek diziler. en azından rutinleşmiş dizi konularından uzak. aile ile rahat rahat izleyebilirsin.  hasan çalık (65-emekli):  kuruluş yıldönümü olduğunu biliyorum. araştırma yaparım. o dönemde yaşamak istemezdim cumhuriyet döneminde yaşamayı daha çok isterdim. okullarda verilen dersler yeterli. film ya da dizi okumak yerine kitap okumayı tercih ederim. bir insan ancak kitap okuyarak aydınlanabilir. bu şekilde kendini geliştirebilir. bir ömre ne kadar kitap sığdırırsan o kadar aydın bir insan olursun. konusu fark etmez ister tarih olsun, ister roman okumak her zaman kazanç sağlar. bir diziden tarihi ne kadar yeterli öğrenebilirsin ki ya da ne kadar doğru anlatılabilir. bence diziyi bırakıp kitaplara yönelsinler.  nuray çelik\n",
      "50 yıldır yükselen enerji: aygaz türk halkını tüpgazla tanıştıran aygaz, 50. kuruluş yılını kutluyor. koç holdi̇ng şeref başkanı ve aygaz yönetîm kurulu başkanı rahmi̇ m. koç,  bugün avrupa nın beşi̇nci̇ büyük lpg şi̇rketi̇ olan aygaz, üreti̇mden dağıtıma uzanan enerji̇ zi̇nci̇ri̇ni̇n tamamına hâki̇m olan yegâne şi̇rketti̇r. li̇der olmak zordur. ama li̇der kalabi̇lmek çok daha zordur  di̇ye konuştu tc  ayoa3 yatırımcı vi̇zyonu kurulduğu 1961 yılından bu yana gazdan petrole, elektrikten madenciliğe kadar enerjinin pek çok alanında faaliyet göstererek, milyonlarca tüketicinin güvenini kazanan koç grubu şirketlerinden aygaz, 50. kuruluş yıldönümünü de enerji sektöründe türkiye nin lider kuruluşlarından biri olarak kutluyor. türkiye de konutlarda, havagazı ve ispirto ocaklarının kullanıldığı yıllarda türk halkını tüpgazla tanıştıran aygaz, yarım asırdır gösterdiği başarılarla avrupa nın beşinci büyük lpg şirketine dönüştü. koç holding şeref başkanı ve aygaz yönetim kurulu başkanı rahmi m. koç, 50. kuruluş yıldönümü nedeniyle yaptığı açıklamada,  bugün avrupa nın beşinci büyük lpg şirketi olan aygaz, üretimden dağıtıma uzanan enerji zincirinin tamamına hakim olan yegane k v-mıfl   şirkettir. lider olmak zordur. ama lider kalabilmek çok daha zordur. aygaz bu zoru başardığı gibi, kendine has yöntemleriyle değişime hızla uyum sağladı ve yerli-yabancı yatırımcıların hep ilgi odağı oldu  dedi.  aygaz her alanda, her i̇şte li̇der oldu   rahmi m. koç, aygaz ın koç holding enerji grubu nun gözbebeği olduğunu belirterek,  kurucumuz rahmetli vehbi koç un da kalbinde çok özel bir yeri olan aygaz a.ş. nin 50. yaşını kutlamak, bizim için sonsuz bir mutluluk vesilesidir  dedi. koç, kurulduğu ilk yıldan itibaren türk halkının güvenini kazanan aygaz ın, türkiye nin en küçük köylerinden en büyük kentlerindeki her evde yerini bulduğunu, çok kısa sürede gazın jenerik adı haline gelmeyi başardığını söyledi. aygaz ın yarım asırlık süre boyunca yatırım yaptığı her alanda, giriştiği her yeni işte liderliğe oturduğunu hatırlatan koç. kurduğu ortaklıklarla da türkiye nin enerji sektöründe söz sahibi bir marka haline geldiğini belirtti. 50 yıllık geçmi̇ş sadece serüveni̇n başlangıcı 50. kuruluş yılı nedeniyle hazırlanan aygaz ın enerji sektökoç holding şeref başkanı ve aygaz yönetim kurulu başkanı rahmi m. koç ründeki yarım asırlık serüvenini anlatan  50 yılın yükselen enerjisi aygaz  başlıklı kitaba da değinen rahmi m. koç, konuşmasını,  aygaz ın 50 yıllık serüveninin başarılı sonucu, başta bayiler, çalışanlar ve hissedarlar olmak üzere tüm paydaşların eseridir. bu kitap, bu serüvenin hikayesini anlatmak ve enerjisini herkese yansıtabilmek için hazırlanmıştır. satırları arasında saklı olan fikir, lider olmayı sürdürebilmek, ikinci 50 yıla aynı dinamik yapıyla devam etmek için gerekli enerjinin, aygaz ın bizzat kendisi olduğudur. türk sanayisinin ve enerji sektörünün yarım yüzyılı geride bırakmış öncü isimlerinden aygaz ın, ülkesi için daha çok yapacakları var. 50 yıllık geçmişi, sadece yeni serüveninin başlangıcıdır  sözleriyle tamamladı.? 30 turi̇zm dünyası\n"
     ]
    }
   ],
   "source": [
    "# Küçük harfe çevirme işlemini uygulayan bir fonksiyon\n",
    "def preprocess_text(example):\n",
    "    example['content'] = example['content'].replace(\"I\", \"ı\").lower()\n",
    "    return example\n",
    "\n",
    "# Train setindeki her bir öğeye işlemi uygulamak\n",
    "dataset['train'] = dataset['train'].map(preprocess_text)\n",
    "\n",
    "# Test setindeki her bir öğeye işlemi uygulamak\n",
    "dataset['test'] = dataset['test'].map(preprocess_text)\n",
    "\n",
    "# Şimdi \"content\" sütunundaki metinler küçük harfe çevrilmiş oldular\n",
    "print(dataset['train'][0]['content'])\n",
    "print(dataset['test'][0]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8ec786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'category'],\n",
      "        num_rows: 218880\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['content', 'category'],\n",
      "        num_rows: 54721\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea598eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset['train']['content']\n",
    "y_train = dataset['train']['category']\n",
    "\n",
    "X_test = dataset['test']['content']\n",
    "y_test = dataset['test']['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e8c45a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_shuffled, y_train_shuffled = shuffle(X_train, y_train, random_state=42)\n",
    "X_test_shuffled, y_test_shuffled = shuffle(X_test, y_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10da4d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eğitim için 5000 örnek ayrıldı\n",
    "subset_size = 5000\n",
    "X_train_sampled = X_train_shuffled[:subset_size]\n",
    "y_train_sampled = y_train_shuffled[:subset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4099e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test için 500 örnek ayrıldı\n",
    "subset_size = 500\n",
    "X_test_sampled = X_test_shuffled[:subset_size]\n",
    "y_test_sampled = y_test_shuffled[:subset_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b92f0fb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: ['bayramda sahillere ineceklere 80 öneri emre tor,bayram için sahillerden 80 öneri bugüne kadar köşemde türkiye nin ve dünyanın farklı yerlerinden yüzlerce tavsiyede bulundum. şimdi sıra bayram önerilerinde. ege ve akdeniz sahilleri bu mevsimde hala çok güzel, gelin sizinle sahillerdeki tatil beldelerinde bulunan favori mekanlarımı paylaşayım böcek serin günlerden sıcak denizlere dunyagezer saffet emre stonguc@hurriyet.com.tr l-i̇da blue hotel  adatepe: huzurun adresi. 2-da costa hotel  assos: alabildiğine ege. 3-teomida hotel  burhaniye: dev bahçe. 4-ortunç hotel  ayvalık: eşsiz koy. 5-ayna restaurant  cunda: balığın en iyisi. 6-mola hotel  cunda: ev rahatlığı. 7-gulet restaurant  küçükkuyu: makul fiyat. 8-limonata hotel  assos: ferah. 9-cihat usta nın yeri  assos: balığın alası. 10-assosyal hotel: şaşırtıcı. ıı  ? m m ı 1-alavya hotel: şık. 2-alancha restaurant: lezzet mabedi. 3-langaza restaurant: sıradışı. 4-köyün delisi bar: çok keyifli. 5-traktör bar: ortam şahane. 6-viento hotel: sıcak. 7-kapari bahçe restaurant: gözde. 8-dondurmino dondurma: orijinal. 9-zio beach plajı: lezzetli sahil. 10-alura hotel: keyifli. bodrum l-caresse luxury collection resort: büyüleyici. 2-11 riccio restaurant: tatlıları dillere destan. 3-no: 81 hotel: 10 numara. 4-kabuk restaurant: özel. 5-limon  gümüşlük: doğanın içinde. . 6-29  tilkicik koyu: yemek ve eğlence. 7-kuumsal restaurant: bademli sufle yıkılıyor. 8-garo s restaurant: kalabalık kaçınılmaz. 9-bella sombra hotel: küçük ama şık. 10- melengeç restaurant: farklı bir alternatif. 1-d maris hotel: dünyanın en iyilerinden. 2-golden key hotel: huzur. 3-zephyros hotel: zole cennet. 4-bozburun yat kulübü: güler yüzlü. 5-i̇ncir restaurant: meze, manzara. 6-sardunya restaurant: başarılı. 7-mehmet ali ağa konağı: geçmişe yolculuk. 8-le jardin de semra: lezzet ve caz. 9-doğan motel: yalın ama hoş. 10-doris hotel: yeni ve güzel. 1-noni s house: kahvaltısı olağanüstü. 2-marge hotel: ılıca nın en güzeli. 3-before sunset plajı: gör-görül. 4-fly-inn plajı: tıka basa dolu. 5-tokmak hasan ın yeri: döner ve kuru fasulye. 6-i̇mren lokantası: tam bir nostalji. 7-kumrucu hüseyin  ılıca: kumrusu 10 numara. 8-dost pide  ılıca: pidenin kralı. 9-yalı balık  şifne yolu: en tazesinden. 10-ada balık: ayaklar denizde. l-breeze restaurant: hak edilmiş fiyat. 2-q lounge: gün batımı. 3-dursun usta et lokantası: etin alası. 4-west cafe: kahvaltı efsane. 5-d-resort: şık mimari. 6-özcan balık restaurant: doğru adres. 7-olive farm: çiftlik ürünleri. 8-dim elit hotel restaurant: denizin üzerinde. 9- sailor s pub: gerçek i̇rlandalı. 10-koylar: tersane, göbün, sarsala, bedri rahmi. 1-tranche restaurant: i̇yi şef. 2-köy sofrası: kirazlı kahvaltı. 3-kazım usta balık restaurant: tek. 4-dilek yarımadası plajları: keyif. 5-7 bilgeler hotel: butik. 6-amara sealight elite hotel: ünlü. 7-avlu esnaf lokantası: ege yemekleri. 8-marina deniz restaurant: şık. 9-selçuk köftecisi: bir efsane. 10-karina balık: çok lezzetli. antalya l-nirvana lagoon suites & spa: adına layık. 2-maxx royal kemer resort: muhteşem koy. 3-kaya palazzo golf resort: orman içinde. 4- regnum carya golf & spa resort: şık. 5-7 mehmet restaurant: mutlaka denenmeli. 6-asmani restaurant: dünya lezzetleri. 7-11 vicino i̇talyan restaurant: i̇talyan lezzetleri. 8-seraser restaurant: rafine lezzet. 9-i̇zmirli nin yeri: ev yemekleri. 10-kaison sushi: uzakdoğu lezzetleri.', 'trafik polisine konya da engelliler için ayrılan bolü na jüme park eden trafik ekip otosu176 tl idari para cezası yazıldı. konya da bir alışveriş merkezinin park alanında engelliler için aynlan bölümde t#k 1      efi#fl trafik polis aracını görenler, fotoğraf çekerek sosyal medyada paylaştı. sayfa 3trafik polisine 176 ti ceza konya da engelliler için ayrılan bölüme park eden trafik ekip otosuna 176 tl idari para cezası yazıldı. konya da bir alışveriş merkezinin park alanında engelliler için ayrılan bölümde trafik polis aracını görenler, fotoğraf çekerek sosyal medyada paylaştı. bu paylaşımın yerel bir gazetede haberleştirilerek,  en çok trafik cezası kesilen şehirlerin başında gelen konya da insanlann trafik kurallanna uymalan konusunda yaptırım gücüne sahip olan trafik ekiplerinin kurallara uymaması dikkat çekti. hata yapan trafik ekiplerine, trafik cezasını kim kesecek sorusu gündeme geldi  başlığıyla birinci sayfada yayınlanması üzerine konya emniyet müdürlüğü harekete geçti. haber ve fotoğraf ihbar kabul edilerek, engelli araç yeridir park yapmayınız. aksi takdirde aracınız çekici ile çekilecektir  yazısına rağmen 42 a 8556 plakalı aracı park eden ekibe taşıt yolu üzerinde özürlülerin araçlan için aynlmış park yerlerinde park etmek suçundan 176 tl idari para cezası uygulandı. konya nın güneysınır ilçesinden bir görev için kent merkezine gelen trafik ekibinin 17 mart salı günü alışveriş merkezine gittiği ve fotoğrafın bu sırada çekildiği öğrenildi. i̇ha', 'y 2015 rpvie vvinner  nti emeklilik müsl eri hizmetleri takımı na  altın ödül  ınternatıonal busıness awards .garanti emeklilik iş dünyasının dm      %uluslararası alanda en prestijli ödül organizasyonlarından stevie ödüllerinde  yılın müşteri hizmetleri takımı  kategorisinde  altın ödül e;  yılın müşteri hizmetleri birimi  kategorisinde de  gümüş ödül e layık görüldü. 2002den bu yana düzenlenen organizasyonda bu yıl, 60 in üzerinde ülkenin farklı sektörlerinden 3 bin 700 u aşkın aday yarıştı. adaylar, dünyanın dört bir taralından 200 un üzerinde yöneticinin yer aldığı jürinin oylarıyla değerlendirildi. garanti emeklilik genel müdür yardımcısı k. çağlayan bakaçhan, ödüllerle ilgili şu değerlendirmeyi yaptı:  stevie ödülleri, uluslararası arenada iş dünyası tarafından büyük saygı gören, çok prestijli bir organizasyon. müşteri memnuniyetim tüm faaliyetlerinin kalbine yerleştiren bir şirket olarak stevie ödüllerinde yılın müşteri hizmetleri takımı kategorisinde altın ödüle ve  yılın müşteri hizmetleri birimi  kategorisinde de gümüş ödüle layık görülmekten büyük mutluluk ve gurur duyduk. garanti f.meklilik olarak, müşteri hizmetleri ekibimizle beklenenin üzerinde müşteri memnuniyeti oluşturarak; eşsiz bir müşteri deneyimi yaşatmak için çalışıyoruz. müşterilerimize her noktada temas etmeyi önemsiyor; onların beklentilerini en doğru şekilde anlamaya, talep ve geri bildirimlerini en hızlı şekilde karşılamaya, yenilikçi ve proaktif çözümler üretmeye odaklanıyoruz.  k. çağlayan bakaçhan']\n",
      "y_train: [0, 0, 1]\n",
      "X_test: ['stadyumlar da kentsel dönüşüm kapsamında ankara- duygu can çevre ve şehircilik bakanlığı, afete dayanıksız olduğu belirlenen stadyumların, kentsel dönüşüm kapsamında yıkılıp yeniden yapılması için maliye ve gençlik ve spor bakanlıklarıyla işbirliğine hazırlanıyor. türkiye nin geleceğini şekillendirmek amacıyla yurt genelinde 5 ekim de başbakan recep tayyip erdoğan ın katıldığı törenle başlatılan kentsel dönüşüm çalışmaları kapsamında, stadyumlar da yenilenecek. kentsel dönüşümle deprem, sel, heyelan gibi afet riski altındaki alanlar ve yapıların yenilenmesini amaçlayan bakanlık, bu kapsamda stadyumları da yıkıp, yerlerine dünya standartlarında yenilerini inşa edecek. 3 bakanlık ortak yürütecek çevre ve şehircilik bakanlığı nın öncü aktör olacağı projeye, maliye ile gençlik ve spor bakanlıkları da destek verecek. öncelikle risk altındaki stadyumlar tespit edilecek. daha sonra yıkılıp, yerine yenisinin yapılması ve maliyeti gibi konular belirlenerek, ortak proje geliştirilecek. konuya ilişkin protokol ise üç bakanlık arasında, kısa bir süre içinde imzalanacak. afet riski altındaki alanların 20 yıllık süreçte dönüştürüleceği uzun soluklu proje kapsamında yeniden inşa edilecek stadyumlar, dünya standartlarına uygun hale getirilecek.    (aa)', 'hırsızlar kameraya yakalandı konya nın ılgın ilçesinde 8 iş yerinden hırsızlık olayına karıştığı öne sürülen kişi, güvenlik kamerası kayıtlarından yola çıkılarak gözaltına alındı. polis, ilçe merkezindeki iş yerlerinden bozuk para, fotoğraf makinesi ve elektronik eşya çalınması üzerine soruşturma başlattı. bir iş yerinin güvenlik kamerası tarafından, bozuk para çalarken görüntülenen şüphelinin sedat d. (21) olduğu belirlendi. akşehir ilçesi otogarında yakalanan şüphelinin, valizinde bin 500 lira bozuk para, fotoğraf makinesi, elektronik eşyalar ele geçiriidi.']\n",
      "y_test: [1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train:\", X_train_sampled[:3])  \n",
    "print(\"y_train:\", y_train_sampled[:3]) \n",
    "\n",
    "print(\"X_test:\", X_test_sampled[:2])\n",
    "print(\"y_test:\", y_test_sampled[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "908ad97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#büyük bert kullanımı\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-turkish-uncased\")\n",
    "model = AutoModel.from_pretrained(\"dbmdz/bert-base-turkish-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12fbce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#büyük bert için bert transformer oluşturulması\n",
    "import torch\n",
    "\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for text in X:\n",
    "            encoded_text = self.tokenizer.encode_plus(\n",
    "                text,\n",
    "                add_special_tokens=True,\n",
    "                max_length=64,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids.append(encoded_text['input_ids'])\n",
    "            attention_masks.append(encoded_text['attention_mask'])\n",
    "\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "        with torch.no_grad():  # Gradyanları hesaplamadan ileri\n",
    "            outputs = self.model(input_ids, attention_mask=attention_masks)\n",
    "            pooled_output = outputs.pooler_output\n",
    "\n",
    "        return pooled_output.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e171f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}\n",
      "En iyi skor: 0.5116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.89      0.62       163\n",
      "           1       0.42      0.63      0.50        82\n",
      "           2       1.00      0.05      0.09        21\n",
      "           3       0.00      0.00      0.00        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.96      0.31      0.47        71\n",
      "           6       0.74      0.34      0.47        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.50      0.38      0.43        13\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.50       500\n",
      "   macro avg       0.41      0.26      0.26       500\n",
      "weighted avg       0.53      0.50      0.44       500\n",
      "\n",
      "Parametreler: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}, Doğruluk: 51.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# ADABOOST\n",
    "\n",
    "# AdaBoostClassifier için pipeline\n",
    "pipeline_ab = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), random_state=42))\n",
    "])\n",
    "\n",
    "# Hiperparametre aralıkları\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_ab = GridSearchCV(pipeline_ab, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Modeli eğitme ve en iyi parametreleri\n",
    "grid_search_ab.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi parametreleri ve sonuçları \n",
    "print(\"En iyi parametreler:\", grid_search_ab.best_params_)\n",
    "print(\"En iyi skor:\", grid_search_ab.best_score_)\n",
    "\n",
    "# Modelin performansını değerlendirin\n",
    "y_pred_ab = grid_search_ab.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_ab))\n",
    "\n",
    "# Her bir kombinasyonun performansı\n",
    "results = grid_search_ab.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0214a5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
      "En iyi skor: 0.759\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.82      0.77       163\n",
      "           1       0.73      0.73      0.73        82\n",
      "           2       0.55      0.52      0.54        21\n",
      "           3       0.76      0.67      0.71        33\n",
      "           4       0.62      0.42      0.50        12\n",
      "           5       0.99      0.93      0.96        71\n",
      "           6       0.78      0.78      0.78        76\n",
      "           7       0.40      0.17      0.24        12\n",
      "           8       0.50      0.62      0.55        13\n",
      "           9       0.92      0.71      0.80        17\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.70      0.64      0.66       500\n",
      "weighted avg       0.76      0.76      0.75       500\n",
      "\n",
      "Parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}, Doğruluk: 75.90%\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM için pipeline \n",
    "pipeline_svm = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Hiperparametre aralıkları\n",
    "param_grid = {\n",
    "    'clf__C': [0.1],\n",
    "    'clf__kernel': ['linear'],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_svm = GridSearchCV(pipeline_svm, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Modeli eğitme ve en iyi parametreler\n",
    "grid_search_svm.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi parametreleri ve sonuçları\n",
    "print(\"En iyi parametreler:\", grid_search_svm.best_params_)\n",
    "print(\"En iyi skor:\", grid_search_svm.best_score_)\n",
    "\n",
    "# Modelin performansını değerlendirin\n",
    "y_pred_svm = grid_search_svm.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_svm))\n",
    "\n",
    "# Her bir kombinasyonun performansı\n",
    "results = grid_search_svm.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1850e4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time= 6.4min\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time= 6.3min\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time= 6.3min\n",
      "En iyi ortalama doğruluk (accuracy) Random Forest: 0.6340009309062556\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.92      0.71       163\n",
      "           1       0.56      0.74      0.64        82\n",
      "           2       0.83      0.24      0.37        21\n",
      "           3       1.00      0.06      0.11        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       1.00      0.75      0.85        71\n",
      "           6       0.79      0.61      0.69        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.42      0.38      0.40        13\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.64       500\n",
      "   macro avg       0.52      0.37      0.38       500\n",
      "weighted avg       0.65      0.64      0.60       500\n",
      "\n",
      "En iyi parametreler Random Forest: {'clf__max_depth': 30, 'clf__min_samples_split': 10, 'clf__n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Random Forest sınıflandırıcıyı ve BERT dönüşümünü kullanarak bir pipeline oluşturmak\n",
    "pipeline_rf = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', RandomForestClassifier())  # Random Forest sınıflandırıcı burada\n",
    "])\n",
    "\n",
    "# Modelin hiperparametre optimizasyonu için bir ızgara araması (GridSearch) yapın (örn. parametreler)\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [150],  # ağaç sayısı\n",
    "    'clf__max_depth': [30],  # Ağaç derinliği için farklı değerler\n",
    "    'clf__min_samples_split': [10]   # Dallanma için gereken minimum örnek sayısı\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi modelin ortalama doğruluğu\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Random Forest:\", best_accuracy_rf)\n",
    "\n",
    "# Modelin performansı\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "# En iyi modelin parametreleri\n",
    "print(\"En iyi parametreler Random Forest:\", grid_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b987c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time= 9.9min\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=10.5min\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=11.1min\n",
      "En iyi ortalama doğruluk (accuracy): 0.6299988501699421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.84      0.70       163\n",
      "           1       0.53      0.74      0.62        82\n",
      "           2       0.54      0.33      0.41        21\n",
      "           3       1.00      0.12      0.22        33\n",
      "           4       1.00      0.17      0.29        12\n",
      "           5       0.93      0.75      0.83        71\n",
      "           6       0.73      0.63      0.68        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.38      0.38      0.38        13\n",
      "           9       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.64       500\n",
      "   macro avg       0.67      0.40      0.42       500\n",
      "weighted avg       0.68      0.64      0.60       500\n",
      "\n",
      "En iyi parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}\n",
      "Parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}, Doğruluk: 63.00%\n"
     ]
    }
   ],
   "source": [
    "# Bagging sınıflandırıcıyı ve BERT dönüşümünü kullanarak bir pipeline oluşturma\n",
    "pipeline = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', BaggingClassifier())\n",
    "])\n",
    "\n",
    "# Modelin hiperparametre optimizasyonu için bir ızgara araması (GridSearch) yapın (örn. parametreler)\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__max_samples': [0.5],\n",
    "    'clf__max_features': [1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi modelin ortalama doğruluğu\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy):\", best_accuracy)\n",
    "\n",
    "# Modelin performansı\n",
    "y_pred = grid_search.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "# En iyi modelin parametreleri\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "\n",
    "# Her bir kombinasyonun performansı\n",
    "results = grid_search.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b0b0ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=10; total time=  10.9s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=10; total time=  10.7s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=10; total time=  11.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=50; total time=  11.2s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=50; total time=  11.8s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=50; total time=  12.9s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=100; total time=  12.3s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=100; total time=  11.9s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=0.5, clf__n_estimators=100; total time=  11.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=10; total time=  10.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=10; total time=  10.9s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=10; total time=  10.5s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=50; total time=  11.8s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=50; total time=  11.8s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=50; total time=  11.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=100; total time=  13.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=100; total time=  12.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.0, clf__n_estimators=100; total time=  12.8s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=10; total time=   6.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=10; total time=   7.5s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=10; total time=   6.9s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=50; total time=   6.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=50; total time=   6.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=50; total time=   7.2s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=100; total time=   7.6s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=100; total time=   6.8s\n",
      "[CV] END clf__max_features=0.5, clf__max_samples=1.5, clf__n_estimators=100; total time=   6.7s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=10; total time=  10.7s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=10; total time=  10.8s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=10; total time=  10.4s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=50; total time=  12.2s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=50; total time=  12.3s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=50; total time=  12.0s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=  13.4s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=  13.8s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=  13.6s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=10; total time=  11.5s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=10; total time=  11.1s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=10; total time=  11.4s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=50; total time=  13.9s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=50; total time=  14.3s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=50; total time=  13.7s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=100; total time=  15.1s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=100; total time=  15.9s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.0, clf__n_estimators=100; total time=  16.0s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=10; total time=   7.3s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=10; total time=   6.8s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=10; total time=   6.7s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=50; total time=   6.7s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=50; total time=   7.3s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=50; total time=   8.3s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=100; total time=   8.0s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=100; total time=   7.1s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=1.5, clf__n_estimators=100; total time=   8.2s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=10; total time=   7.1s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=10; total time=   7.3s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=10; total time=   7.6s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=50; total time=   7.4s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=50; total time=   8.2s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=50; total time=   7.1s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=100; total time=   7.0s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=100; total time=   7.2s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=0.5, clf__n_estimators=100; total time=   7.6s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=10; total time=   6.9s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=10; total time=   7.1s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=10; total time=   6.9s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=50; total time=   7.8s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=50; total time=   7.9s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=50; total time=   7.3s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=100; total time=   7.2s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=100; total time=   7.2s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.0, clf__n_estimators=100; total time=   7.4s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=10; total time=   7.0s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=10; total time=   6.8s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=10; total time=   7.0s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=50; total time=   7.0s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=50; total time=   7.0s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=50; total time=   7.0s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=100; total time=   6.9s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=100; total time=   7.8s\n",
      "[CV] END clf__max_features=1.5, clf__max_samples=1.5, clf__n_estimators=100; total time=   7.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "45 fits failed out of a total of 81.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 326, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_samples' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0, 1]. Got 1.5 instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 326, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of BaggingClassifier must be an int in the range [1, inf) or a float in the range (0, 1]. Got 1.5 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.475049   0.53987638 0.52532791 0.50007538 0.54990201 0.55005277\n",
      "        nan        nan        nan 0.44534901 0.52510176 0.56030454\n",
      " 0.5202774  0.53527815 0.53037841        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       1.00      0.50      0.67         2\n",
      "           8       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.43      0.38      0.39        10\n",
      "weighted avg       0.64      0.60      0.60        10\n",
      "\n",
      "En iyi parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Bagging sınıflandırıcıyı ve BERT dönüşümünü kullanarak bir pipeline oluşturma\n",
    "pipeline = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', BaggingClassifier())\n",
    "])\n",
    "\n",
    "# Modelin hiperparametre optimizasyonu için bir ızgara araması (GridSearch) yapın (örn. parametreler)\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [10, 50, 100],\n",
    "    'clf__max_samples': [0.5, 1.0, 1.5],\n",
    "    'clf__max_features': [0.5, 1.0, 1.5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=3, verbose=2)\n",
    "grid_search.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi modelin ortalama doğruluğu\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy):\", best_accuracy)\n",
    "\n",
    "# Modelin performansı\n",
    "y_pred = grid_search.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "# En iyi modelin parametreleri\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96279170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=18.4min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=17.0min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=14.6min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=14.8min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=14.7min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=14.9min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=26.1min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=22.9min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=23.1min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=23.1min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=23.1min\n",
      "[CV] END clf__max_group=3, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=23.4min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 3.5min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 3.8min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 3.6min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time= 3.5min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time= 3.7min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time= 4.6min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 4.5min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 4.6min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 4.6min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time= 4.5min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time= 4.5min\n",
      "[CV] END clf__max_group=3, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time= 4.0min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=16.0min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=16.0min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=15.0min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=15.2min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=13.0min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=14.8min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=25.0min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=24.5min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=21.9min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=21.1min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=25.3min\n",
      "[CV] END clf__max_group=5, clf__min_group=3, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=21.7min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=13.5min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=12.8min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=12.7min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=12.8min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=12.9min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=100, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=12.8min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=19.4min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=19.4min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=19.4min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=23.6min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=20.7min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.7; total time=18.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "12 fits failed out of a total of 48.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sktime\\classification\\sklearn\\_rotation_forest.py\", line 241, in fit\n",
      "    fit = Parallel(n_jobs=self._n_jobs)(\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1098, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 975, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 567, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 445, in result\n",
      "    return self.__get_result()\n",
      "  File \"C:\\Users\\havva\\anaconda3\\lib\\concurrent\\futures\\_base.py\", line 390, in __get_result\n",
      "    raise self._exception\n",
      "ValueError: negative dimensions are not allowed\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.66259965 0.66439857 0.66599945 0.66699973        nan        nan\n",
      "        nan        nan 0.66660017 0.66779969 0.66419981 0.66499929\n",
      " 0.66460069 0.66680013 0.67060045 0.66819877]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi ortalama doğruluk (accuracy) Rotation Forest: 0.6706004537387841\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.86      0.74       163\n",
      "           1       0.61      0.80      0.69        82\n",
      "           2       0.69      0.52      0.59        21\n",
      "           3       0.90      0.27      0.42        33\n",
      "           4       1.00      0.33      0.50        12\n",
      "           5       0.95      0.82      0.88        71\n",
      "           6       0.81      0.68      0.74        76\n",
      "           7       1.00      0.08      0.15        12\n",
      "           8       0.47      0.54      0.50        13\n",
      "           9       1.00      0.29      0.45        17\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.81      0.52      0.57       500\n",
      "weighted avg       0.75      0.71      0.69       500\n",
      "\n",
      "En iyi parametreler Rotation Forest: {'clf__max_group': 5, 'clf__min_group': 5, 'clf__n_estimators': 150, 'clf__n_jobs': -1, 'clf__remove_proportion': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#rotation forest\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "rotation_tree_clf = RotationTreeClassifier()\n",
    "\n",
    "# rotation Forest sınıflandırıcıyı ve BERT dönüşümünü kullanarak bir pipeline oluşturma\n",
    "pipeline_rotation_forest = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf',  RotationForest())\n",
    "])\n",
    "\n",
    "param_grid_rotation_forest = {\n",
    "    'clf__n_estimators': [100, 150],\n",
    "    'clf__min_group': [3, 5],\n",
    "    'clf__max_group': [3, 5],\n",
    "    'clf__remove_proportion': [0.5, 0.7],\n",
    "    'clf__n_jobs': [-1],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rotation_forest, param_grid_rotation_forest,scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi modelin ortalama doğruluğu\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Rotation Forest:\", best_accuracy_rf)\n",
    "\n",
    "# Modelin performansı\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "# En iyi modelin parametreleri\n",
    "print(\"En iyi parametreler Rotation Forest:\", grid_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9133f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "#mini bert kullanımı \n",
    "model = AutoModel.from_pretrained(\"ytu-ce-cosmos/turkish-mini-bert-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-mini-bert-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fb57b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, tokenizer, max_length=64, batch_size=8):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for i in range(0, len(X), self.batch_size):\n",
    "            batch_texts = X[i:i+self.batch_size]\n",
    "            batch_encoded_texts = self.tokenizer.batch_encode_plus(\n",
    "                batch_texts,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids.append(batch_encoded_texts['input_ids'])\n",
    "            attention_masks.append(batch_encoded_texts['attention_mask'])\n",
    "\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask=attention_masks)\n",
    "            pooled_output = outputs.last_hidden_state.mean(dim=1)  # Ortalama al\n",
    "            # pooled_output = outputs.pooler_output  # Bu satırı kullanmak yerine ortalama almayı tercih ettim\n",
    "\n",
    "        return pooled_output.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97116c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time= 1.7min\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time= 1.7min\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time= 1.7min\n",
      "En iyi ortalama doğruluk (accuracy): 0.6791981339626432\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Bagging sınıflandırıcıyı ve BERT dönüşümünü kullanarak bir pipeline oluşturma\n",
    "pipeline = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', BaggingClassifier())\n",
    "])\n",
    "\n",
    "# Modelin hiperparametre optimizasyonu için bir ızgara araması (GridSearch) yapın (örn. parametreler)\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__max_samples': [0.5],\n",
    "    'clf__max_features': [1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi modelin ortalama doğruluğunu alma\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy):\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f31dff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       163\n",
      "           1       0.63      0.78      0.70        82\n",
      "           2       0.80      0.38      0.52        21\n",
      "           3       1.00      0.18      0.31        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.89      0.80      0.84        71\n",
      "           6       0.76      0.66      0.70        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.44      0.54      0.48        13\n",
      "           9       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.61      0.43      0.44       500\n",
      "weighted avg       0.68      0.67      0.63       500\n",
      "\n",
      "En iyi parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}\n",
      "Parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}, Doğruluk: 67.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "# En iyi modelin parametrelerini görüntüleme\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "\n",
    "# Her bir kombinasyonun performansı\n",
    "results = grid_search.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6bf7dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}\n",
      "Best score: 0.4822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.86      0.71       163\n",
      "           1       0.63      0.78      0.70        82\n",
      "           2       0.80      0.38      0.52        21\n",
      "           3       1.00      0.18      0.31        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.89      0.80      0.84        71\n",
      "           6       0.76      0.66      0.70        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.44      0.54      0.48        13\n",
      "           9       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.67       500\n",
      "   macro avg       0.61      0.43      0.44       500\n",
      "weighted avg       0.68      0.67      0.63       500\n",
      "\n",
      "Parameters: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}, Accuracy: 48.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#adaboost\n",
    "\n",
    "pipeline_ab = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_ab = GridSearchCV(pipeline_ab, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "\n",
    "grid_search_ab.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", grid_search_ab.best_params_)\n",
    "print(\"Best score:\", grid_search_ab.best_score_)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "\n",
    "results = grid_search_ab.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parameters: {params}, Accuracy: {mean_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "548ec351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
      "En iyi skor: 0.7736000000000001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       163\n",
      "           1       0.76      0.80      0.78        82\n",
      "           2       0.75      0.57      0.65        21\n",
      "           3       0.72      0.64      0.68        33\n",
      "           4       0.75      0.50      0.60        12\n",
      "           5       0.94      0.94      0.94        71\n",
      "           6       0.79      0.80      0.80        76\n",
      "           7       0.71      0.42      0.53        12\n",
      "           8       0.39      0.69      0.50        13\n",
      "           9       0.91      0.59      0.71        17\n",
      "\n",
      "    accuracy                           0.77       500\n",
      "   macro avg       0.75      0.67      0.70       500\n",
      "weighted avg       0.78      0.77      0.77       500\n",
      "\n",
      "Parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}, Doğruluk: 77.36%\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM için pipeline \n",
    "pipeline_svm = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Hiperparametre aralıkları\n",
    "param_grid = {\n",
    "    'clf__C': [0.1],\n",
    "    'clf__kernel': ['linear'],\n",
    "}\n",
    "\n",
    "# GridSearchCVç\n",
    "grid_search_svm = GridSearchCV(pipeline_svm, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Modeli eğitme ve en iyi parametreler\n",
    "grid_search_svm.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi parametreleri ve sonuçları\n",
    "print(\"En iyi parametreler:\", grid_search_svm.best_params_)\n",
    "print(\"En iyi skor:\", grid_search_svm.best_score_)\n",
    "\n",
    "# Modelin performansı\n",
    "y_pred_svm = grid_search_svm.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_svm))\n",
    "\n",
    "# Her bir kombinasyonun performansı\n",
    "results = grid_search_svm.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9230fea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time=  37.3s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time=  37.2s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time=  37.2s\n",
      "En iyi ortalama doğruluk (accuracy) Random Forest: 0.6865990547388722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.92      0.75       163\n",
      "           1       0.65      0.80      0.72        82\n",
      "           2       1.00      0.43      0.60        21\n",
      "           3       1.00      0.21      0.35        33\n",
      "           4       1.00      0.08      0.15        12\n",
      "           5       0.98      0.83      0.90        71\n",
      "           6       0.79      0.71      0.75        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.47      0.54      0.50        13\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.65      0.45      0.47       500\n",
      "weighted avg       0.72      0.71      0.67       500\n",
      "\n",
      "En iyi parametreler Random Forest: {'clf__max_depth': 30, 'clf__min_samples_split': 10, 'clf__n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', RandomForestClassifier())  # Random Forest sınıflandırıcı burada\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [150], \n",
    "    'clf__max_depth': [30],  \n",
    "    'clf__min_samples_split': [10]    \n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Random Forest:\", best_accuracy_rf)\n",
    "\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "print(\"En iyi parametreler Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f7cc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 5.5min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 5.3min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 5.4min\n",
      "En iyi ortalama doğruluk (accuracy) Rotation Forest: 0.7196001375955302\n"
     ]
    }
   ],
   "source": [
    "#rotation forest\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "rotation_tree_clf = RotationTreeClassifier()\n",
    "\n",
    "pipeline_rotation_forest = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf',  RotationForest())\n",
    "])\n",
    "\n",
    "param_grid_rotation_forest = {\n",
    "    'clf__n_estimators': [150],\n",
    "    'clf__min_group': [5],\n",
    "    'clf__max_group': [5],\n",
    "    'clf__remove_proportion': [0.5],\n",
    "    'clf__n_jobs': [-1],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rotation_forest, param_grid_rotation_forest,scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Rotation Forest:\", best_accuracy_rf)\n",
    "\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "print(\"En iyi parametreler Rotation Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3112d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMALL BERT\n",
    " \n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\"ytu-ce-cosmos/turkish-small-bert-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-small-bert-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df612149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, tokenizer, max_length=64, batch_size=8):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for i in range(0, len(X), self.batch_size):\n",
    "            batch_texts = X[i:i+self.batch_size]\n",
    "            batch_encoded_texts = self.tokenizer.batch_encode_plus(\n",
    "                batch_texts,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids.append(batch_encoded_texts['input_ids'])\n",
    "            attention_masks.append(batch_encoded_texts['attention_mask'])\n",
    "\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask=attention_masks)\n",
    "            pooled_output = outputs.last_hidden_state.mean(dim=1)  # Ortalama al\n",
    "            # pooled_output = outputs.pooler_output  # Bu satırı kullanmak yerine ortalama almayı tercih ettim\n",
    "\n",
    "        return pooled_output.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "818b34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time= 3.3min\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time= 2.7min\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time= 2.7min\n",
      "En iyi ortalama doğruluk (accuracy): 0.6779981338666241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74       163\n",
      "           1       0.67      0.85      0.75        82\n",
      "           2       0.78      0.33      0.47        21\n",
      "           3       0.82      0.27      0.41        33\n",
      "           4       1.00      0.17      0.29        12\n",
      "           5       1.00      0.83      0.91        71\n",
      "           6       0.79      0.74      0.76        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.42      0.38      0.40        13\n",
      "           9       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.71       500\n",
      "   macro avg       0.71      0.45      0.48       500\n",
      "weighted avg       0.73      0.71      0.68       500\n",
      "\n",
      "En iyi parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}\n",
      "Parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}, Doğruluk: 67.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', BaggingClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__max_samples': [0.5],\n",
    "    'clf__max_features': [1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy):\", best_accuracy)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "\n",
    "results = grid_search.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cddea42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}\n",
      "Best score: 0.502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.63       163\n",
      "           1       0.48      0.62      0.54        82\n",
      "           2       1.00      0.10      0.17        21\n",
      "           3       0.00      0.00      0.00        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       1.00      0.49      0.66        71\n",
      "           6       0.75      0.39      0.52        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       1.00      0.08      0.14        13\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.54       500\n",
      "   macro avg       0.47      0.26      0.27       500\n",
      "weighted avg       0.56      0.54      0.48       500\n",
      "\n",
      "Parameters: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}, Accuracy: 50.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#adaboost\n",
    "\n",
    "pipeline_ab = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "grid_search_ab = GridSearchCV(pipeline_ab, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "grid_search_ab.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "print(\"Best parameters:\", grid_search_ab.best_params_)\n",
    "print(\"Best score:\", grid_search_ab.best_score_)\n",
    "\n",
    "y_pred = grid_search_ab.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "results = grid_search_ab.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parameters: {params}, Accuracy: {mean_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "795e868f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
      "En iyi skor: 0.7924\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79       163\n",
      "           1       0.80      0.79      0.80        82\n",
      "           2       0.67      0.57      0.62        21\n",
      "           3       0.79      0.82      0.81        33\n",
      "           4       0.50      0.50      0.50        12\n",
      "           5       0.99      0.93      0.96        71\n",
      "           6       0.78      0.84      0.81        76\n",
      "           7       0.50      0.33      0.40        12\n",
      "           8       0.44      0.62      0.52        13\n",
      "           9       0.93      0.76      0.84        17\n",
      "\n",
      "    accuracy                           0.79       500\n",
      "   macro avg       0.72      0.70      0.70       500\n",
      "weighted avg       0.79      0.79      0.79       500\n",
      "\n",
      "Parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}, Doğruluk: 79.24%\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM için pipeline \n",
    "pipeline_svm = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Hiperparametre aralıkları\n",
    "param_grid = {\n",
    "    'clf__C': [0.1],\n",
    "    'clf__kernel': ['linear'],\n",
    "}\n",
    "\n",
    "# GridSearchCVç\n",
    "grid_search_svm = GridSearchCV(pipeline_svm, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Modeli eğitme ve en iyi parametreler\n",
    "grid_search_svm.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi parametreleri ve sonuçları\n",
    "print(\"En iyi parametreler:\", grid_search_svm.best_params_)\n",
    "print(\"En iyi skor:\", grid_search_svm.best_score_)\n",
    "\n",
    "# Modelin performansıı\n",
    "y_pred_svm = grid_search_svm.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_svm))\n",
    "\n",
    "# Her bir kombinasyonun performansı\n",
    "results = grid_search_svm.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "960f97b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time= 1.0min\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time= 1.0min\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time= 1.1min\n",
      "En iyi ortalama doğruluk (accuracy) Random Forest: 0.6759994939787553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72       163\n",
      "           1       0.61      0.76      0.67        82\n",
      "           2       1.00      0.33      0.50        21\n",
      "           3       1.00      0.09      0.17        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       1.00      0.86      0.92        71\n",
      "           6       0.79      0.72      0.75        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.50      0.38      0.43        13\n",
      "           9       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.65      0.41      0.43       500\n",
      "weighted avg       0.71      0.68      0.64       500\n",
      "\n",
      "En iyi parametreler Random Forest: {'clf__max_depth': 30, 'clf__min_samples_split': 10, 'clf__n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', RandomForestClassifier())  # Random Forest sınıflandırıcı burada\n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [150],\n",
    "    'clf__max_depth': [30],  \n",
    "    'clf__min_samples_split': [10]  \n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Random Forest:\", best_accuracy_rf)\n",
    "\n",
    "\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "\n",
    "print(\"En iyi parametreler Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e17196e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=19.5min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=16.0min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time=10.7min\n",
      "En iyi ortalama doğruluk (accuracy) Rotation Forest: 0.7262002581476502\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77       163\n",
      "           1       0.71      0.83      0.76        82\n",
      "           2       0.75      0.43      0.55        21\n",
      "           3       0.72      0.39      0.51        33\n",
      "           4       0.67      0.17      0.27        12\n",
      "           5       1.00      0.90      0.95        71\n",
      "           6       0.87      0.76      0.81        76\n",
      "           7       0.50      0.08      0.14        12\n",
      "           8       0.50      0.54      0.52        13\n",
      "           9       1.00      0.29      0.45        17\n",
      "\n",
      "    accuracy                           0.75       500\n",
      "   macro avg       0.74      0.53      0.57       500\n",
      "weighted avg       0.76      0.75      0.73       500\n",
      "\n",
      "En iyi parametreler Rotation Forest: {'clf__max_group': 5, 'clf__min_group': 5, 'clf__n_estimators': 150, 'clf__n_jobs': -1, 'clf__remove_proportion': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#rotation forest\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "rotation_tree_clf = RotationTreeClassifier()\n",
    "\n",
    "\n",
    "pipeline_rotation_forest = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf',  RotationForest())\n",
    "])\n",
    "\n",
    "param_grid_rotation_forest = {\n",
    "    'clf__n_estimators': [150],\n",
    "    'clf__min_group': [5],\n",
    "    'clf__max_group': [5],\n",
    "    'clf__remove_proportion': [0.5],\n",
    "    'clf__n_jobs': [-1],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rotation_forest, param_grid_rotation_forest,scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Rotation Forest:\", best_accuracy_rf)\n",
    "\n",
    "\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "\n",
    "print(\"En iyi parametreler Rotation Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bd987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TINY BERT\n",
    " \n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model = AutoModel.from_pretrained(\"ytu-ce-cosmos/turkish-tiny-bert-uncased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ytu-ce-cosmos/turkish-tiny-bert-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5159b0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from transformers import AutoTokenizer, BertForMaskedLM\n",
    "\n",
    "class BertTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model, tokenizer, max_length=64, batch_size=8):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        input_ids = []\n",
    "        attention_masks = []\n",
    "\n",
    "        for i in range(0, len(X), self.batch_size):\n",
    "            batch_texts = X[i:i+self.batch_size]\n",
    "            batch_encoded_texts = self.tokenizer.batch_encode_plus(\n",
    "                batch_texts,\n",
    "                add_special_tokens=True,\n",
    "                max_length=self.max_length,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "\n",
    "            input_ids.append(batch_encoded_texts['input_ids'])\n",
    "            attention_masks.append(batch_encoded_texts['attention_mask'])\n",
    "\n",
    "        input_ids = torch.cat(input_ids, dim=0)\n",
    "        attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask=attention_masks)\n",
    "            pooled_output = outputs.last_hidden_state.mean(dim=1)  # Ortalama al\n",
    "            # pooled_output = outputs.pooler_output  # Bu satırı kullanmak yerine ortalama almayı tercih ettim\n",
    "\n",
    "        return pooled_output.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "562f008b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}\n",
      "Best score: 0.5471999999999999\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.65       163\n",
      "           1       0.55      0.59      0.56        82\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       1.00      0.03      0.06        33\n",
      "           4       0.00      0.00      0.00        12\n",
      "           5       0.98      0.63      0.77        71\n",
      "           6       0.79      0.50      0.61        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.25      0.08      0.12        13\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.57       500\n",
      "   macro avg       0.41      0.28      0.28       500\n",
      "weighted avg       0.58      0.57      0.51       500\n",
      "\n",
      "Parameters: {'clf__learning_rate': 0.1, 'clf__n_estimators': 100}, Accuracy: 54.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#adaboost\n",
    "\n",
    "pipeline_ab = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), random_state=42))\n",
    "])\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_ab = GridSearchCV(pipeline_ab, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "\n",
    "grid_search_ab.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", grid_search_ab.best_params_)\n",
    "print(\"Best score:\", grid_search_ab.best_score_)\n",
    "\n",
    "y_pred = grid_search_ab.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "results = grid_search_ab.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parameters: {params}, Accuracy: {mean_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2b21c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}\n",
      "En iyi skor: 0.751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.87      0.76       163\n",
      "           1       0.78      0.76      0.77        82\n",
      "           2       0.77      0.48      0.59        21\n",
      "           3       0.74      0.52      0.61        33\n",
      "           4       1.00      0.50      0.67        12\n",
      "           5       0.99      0.93      0.96        71\n",
      "           6       0.81      0.82      0.81        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.47      0.69      0.56        13\n",
      "           9       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.76       500\n",
      "   macro avg       0.71      0.60      0.63       500\n",
      "weighted avg       0.76      0.76      0.75       500\n",
      "\n",
      "Parametreler: {'clf__C': 0.1, 'clf__kernel': 'linear'}, Doğruluk: 75.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SVM için pipeline \n",
    "pipeline_svm = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', SVC())\n",
    "])\n",
    "\n",
    "# Hiperparametre aralıkları\n",
    "param_grid = {\n",
    "    'clf__C': [0.1],\n",
    "    'clf__kernel': ['linear'],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_svm = GridSearchCV(pipeline_svm, param_grid, scoring='accuracy', cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))\n",
    "\n",
    "# Modeli eğitme ve en iyi parametreler\n",
    "grid_search_svm.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# En iyi parametreleri ve sonuçları\n",
    "print(\"En iyi parametreler:\", grid_search_svm.best_params_)\n",
    "print(\"En iyi skor:\", grid_search_svm.best_score_)\n",
    "\n",
    "# Modelin performansı\n",
    "y_pred_svm = grid_search_svm.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_svm))\n",
    "\n",
    "# Her bir kombinasyonun performansı\n",
    "results = grid_search_svm.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdaea19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time=  15.5s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time=  17.0s\n",
      "[CV] END clf__max_depth=30, clf__min_samples_split=10, clf__n_estimators=150; total time=  16.7s\n",
      "En iyi ortalama doğruluk (accuracy) Random Forest: 0.6889980947387954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.90      0.74       163\n",
      "           1       0.64      0.78      0.70        82\n",
      "           2       0.83      0.24      0.37        21\n",
      "           3       0.69      0.27      0.39        33\n",
      "           4       1.00      0.08      0.15        12\n",
      "           5       0.98      0.86      0.92        71\n",
      "           6       0.78      0.75      0.77        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.57      0.62      0.59        13\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.70       500\n",
      "   macro avg       0.61      0.45      0.46       500\n",
      "weighted avg       0.69      0.70      0.66       500\n",
      "\n",
      "En iyi parametreler Random Forest: {'clf__max_depth': 30, 'clf__min_samples_split': 10, 'clf__n_estimators': 150}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', RandomForestClassifier())  \n",
    "])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'clf__n_estimators': [150],  \n",
    "    'clf__max_depth': [30], \n",
    "    'clf__min_samples_split': [10] \n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Random Forest:\", best_accuracy_rf)\n",
    "\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "print(\"En iyi parametreler Random Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65a8de77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 2.5min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 2.7min\n",
      "[CV] END clf__max_group=5, clf__min_group=5, clf__n_estimators=150, clf__n_jobs=-1, clf__remove_proportion=0.5; total time= 2.8min\n",
      "En iyi ortalama doğruluk (accuracy) Rotation Forest: 0.7107976964030963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.89      0.75       163\n",
      "           1       0.68      0.72      0.70        82\n",
      "           2       0.60      0.29      0.39        21\n",
      "           3       0.71      0.36      0.48        33\n",
      "           4       0.75      0.25      0.38        12\n",
      "           5       1.00      0.87      0.93        71\n",
      "           6       0.80      0.80      0.80        76\n",
      "           7       0.50      0.08      0.14        12\n",
      "           8       0.42      0.62      0.50        13\n",
      "           9       1.00      0.06      0.11        17\n",
      "\n",
      "    accuracy                           0.72       500\n",
      "   macro avg       0.71      0.49      0.52       500\n",
      "weighted avg       0.73      0.72      0.69       500\n",
      "\n",
      "En iyi parametreler Rotation Forest: {'clf__max_group': 5, 'clf__min_group': 5, 'clf__n_estimators': 150, 'clf__n_jobs': -1, 'clf__remove_proportion': 0.5}\n"
     ]
    }
   ],
   "source": [
    "#rotation forest\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "rotation_tree_clf = RotationTreeClassifier()\n",
    "\n",
    "pipeline_rotation_forest = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf',  RotationForest())\n",
    "])\n",
    "\n",
    "param_grid_rotation_forest = {\n",
    "    'clf__n_estimators': [150],\n",
    "    'clf__min_group': [5],\n",
    "    'clf__max_group': [5],\n",
    "    'clf__remove_proportion': [0.5],\n",
    "    'clf__n_jobs': [-1],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_rf = GridSearchCV(pipeline_rotation_forest, param_grid_rotation_forest,scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search_rf.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "best_accuracy_rf = grid_search_rf.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy) Rotation Forest:\", best_accuracy_rf)\n",
    "\n",
    "y_pred_rf = grid_search_rf.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred_rf))\n",
    "\n",
    "print(\"En iyi parametreler Rotation Forest:\", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d62c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=  36.2s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=  38.7s\n",
      "[CV] END clf__max_features=1.0, clf__max_samples=0.5, clf__n_estimators=100; total time=  47.7s\n",
      "En iyi ortalama doğruluk (accuracy): 0.6833974141546241\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.73       163\n",
      "           1       0.64      0.73      0.68        82\n",
      "           2       0.50      0.24      0.32        21\n",
      "           3       0.69      0.33      0.45        33\n",
      "           4       0.50      0.08      0.14        12\n",
      "           5       0.95      0.83      0.89        71\n",
      "           6       0.76      0.71      0.73        76\n",
      "           7       0.00      0.00      0.00        12\n",
      "           8       0.41      0.54      0.47        13\n",
      "           9       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.68       500\n",
      "   macro avg       0.51      0.43      0.44       500\n",
      "weighted avg       0.65      0.68      0.65       500\n",
      "\n",
      "En iyi parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}\n",
      "Parametreler: {'clf__max_features': 1.0, 'clf__max_samples': 0.5, 'clf__n_estimators': 100}, Doğruluk: 68.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\havva\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bert', BertTransformer(model, tokenizer)),\n",
    "    ('clf', BaggingClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__n_estimators': [100],\n",
    "    'clf__max_samples': [0.5],\n",
    "    'clf__max_features': [1.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, scoring='accuracy', cv=3, verbose=2)\n",
    "grid_search.fit(X_train_sampled, y_train_sampled)\n",
    "\n",
    "best_accuracy = grid_search.best_score_\n",
    "print(\"En iyi ortalama doğruluk (accuracy):\", best_accuracy)\n",
    "\n",
    "y_pred = grid_search.predict(X_test_sampled)\n",
    "print(classification_report(y_test_sampled, y_pred))\n",
    "\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "\n",
    "results = grid_search.cv_results_\n",
    "for mean_score, params in zip(results['mean_test_score'], results['params']):\n",
    "    print(f\"Parametreler: {params}, Doğruluk: {mean_score * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
